from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from openai import OpenAI
import requests
import os
import base64
from typing import Optional

app = FastAPI()

# CORS configuration
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialize OpenAI client
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Sightengine credentials
SIGHTENGINE_USER = os.getenv("SIGHTENGINE_USER")
SIGHTENGINE_SECRET = os.getenv("SIGHTENGINE_SECRET")

# Hive AI credentials
HIVE_API_KEY = os.getenv("HIVE_API_KEY")


class ProfileRequest(BaseModel):
    username: str
    bio: str
    posts_count: int
    followers_count: int
    following_count: int


class PhotoRequest(BaseModel):
    photo_url: Optional[str] = None
    image_base64: Optional[str] = None


@app.get("/")
def read_root():
    return {"status": "ok", "message": "Instagram Analyzer API is running"}


@app.post("/analyze")
async def analyze_profile(request: ProfileRequest):
    """Analyze Instagram profile using GPT-4o-mini"""
    try:
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π Instagram –ø—Ä–æ—Ñ–∏–ª—å –∏ –¥–∞–π –¥–µ—Ç–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É:

–ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {request.username}
–ë–∏–æ–≥—Ä–∞—Ñ–∏—è: {request.bio}
–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–æ–≤: {request.posts_count}
–ü–æ–¥–ø–∏—Å—á–∏–∫–∏: {request.followers_count}
–ü–æ–¥–ø–∏—Å–∫–∏: {request.following_count}

–î–∞–π –∞–Ω–∞–ª–∏–∑ –ø–æ —Å–ª–µ–¥—É—é—â–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º:
1. üéØ –û—Ü–µ–Ω–∫–∞ –ø–æ–¥–ª–∏–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–æ—Ñ–∏–ª—è (0-100%)
2. üìä –ê–Ω–∞–ª–∏–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏ –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏
3. üîç –ü—Ä–∏–∑–Ω–∞–∫–∏ –±–æ—Ç–∞ –∏–ª–∏ —Ñ–µ–π–∫–æ–≤–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞
4. üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Å emoji –∏ —Ä–∞–∑–¥–µ–ª–∞–º–∏."""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–π. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1000
        )

        return {"analysis": response.choices[0].message.content}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


def get_image_bytes(photo_url: Optional[str], image_base64: Optional[str]) -> bytes:
    """Get image bytes from URL or base64 string"""
    if image_base64:
        # Remove data URL prefix if present
        if ',' in image_base64:
            image_base64 = image_base64.split(',')[1]
        return base64.b64decode(image_base64)
    elif photo_url:
        response = requests.get(photo_url, timeout=30)
        response.raise_for_status()
        return response.content
    else:
        raise ValueError("Either photo_url or image_base64 must be provided")


def analyze_with_gpt4_vision(photo_url: Optional[str], image_base64: Optional[str]) -> dict:
    """Analyze photo using GPT-4 Vision for filter and manipulation detection"""
    result = {
        "has_filters": None,
        "filter_type": None,
        "manipulation_signs": None,
        "authenticity_score": None,
        "analysis": None,
        "error": None
    }
    
    try:
        # Prepare image for GPT-4 Vision
        if image_base64:
            # Ensure proper base64 format
            if ',' in image_base64:
                image_data = image_base64
            else:
                image_data = f"data:image/jpeg;base64,{image_base64}"
        else:
            image_data = photo_url
        
        prompt = """–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ —Ñ–æ—Ç–æ –∏ –æ–ø—Ä–µ–¥–µ–ª–∏:

1. –§–ò–õ–¨–¢–†–´ –ò –ú–ê–°–ö–ò:
- –ï—Å—Ç—å –ª–∏ –Ω–∞ —Ñ–æ—Ç–æ —Ñ–∏–ª—å—Ç—Ä—ã Snapchat, Instagram, TikTok –∏–ª–∏ –¥—Ä—É–≥–∏—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π?
- –ö–∞–∫–æ–π —Ç–∏–ø —Ñ–∏–ª—å—Ç—Ä–∞ (–º–∞—Å–∫–∞ –Ω–∞ –ª–∏—Ü–æ, —ç—Ñ—Ñ–µ–∫—Ç—ã, —É–∫—Ä–∞—à–µ–Ω–∏—è, –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤–Ω–µ—à–Ω–æ—Å—Ç–∏)?
- –ù–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω–æ —Ñ–∏–ª—å—Ç—Ä –∏–∑–º–µ–Ω—è–µ—Ç –≤–Ω–µ—à–Ω–æ—Å—Ç—å (—Å–ª–∞–±–æ/—Å—Ä–µ–¥–Ω–µ/—Å–∏–ª—å–Ω–æ)?

2. –û–ë–†–ê–ë–û–¢–ö–ê –§–û–¢–û:
- –ï—Å—Ç—å –ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–µ—Ç—É—à–∏ –∏–ª–∏ —Ñ–æ—Ç–æ—à–æ–ø–∞?
- –ï—Å—Ç—å –ª–∏ –±—å—é—Ç–∏-—Ñ–∏–ª—å—Ç—Ä—ã (—Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –∫–æ–∂–∏, —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –≥–ª–∞–∑, –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º—ã –ª–∏—Ü–∞)?
- –ï—Å—Ç—å –ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–Ω–µ–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–µ—Ç–∞–ª–∏, –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã)?

3. –û–¶–ï–ù–ö–ê –ü–û–î–õ–ò–ù–ù–û–°–¢–ò:
- –î–∞–π –æ—Ü–µ–Ω–∫—É –æ—Ç 0 –¥–æ 100%, –≥–¥–µ 100% = –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–∞—Ç—É—Ä–∞–ª—å–Ω–æ–µ —Ñ–æ—Ç–æ –±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏

–û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
–§–ò–õ–¨–¢–†–´: [–î–∞/–ù–µ—Ç] - [—Ç–∏–ø —Ñ–∏–ª—å—Ç—Ä–∞ –µ—Å–ª–∏ –µ—Å—Ç—å]
–û–ë–†–ê–ë–û–¢–ö–ê: [–æ–ø–∏—Å–∞–Ω–∏–µ]
–ü–û–î–õ–ò–ù–ù–û–°–¢–¨: [—á–∏—Å–ª–æ]%
–í–´–í–û–î: [–∫—Ä–∞—Ç–∫–∏–π –≤—ã–≤–æ–¥]"""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {"url": image_data}
                        }
                    ]
                }
            ],
            max_tokens=500
        )
        
        analysis_text = response.choices[0].message.content
        result["analysis"] = analysis_text
        
        # Parse the response
        lines = analysis_text.upper()
        
        # Check for filters
        if "–§–ò–õ–¨–¢–†–´: –î–ê" in lines or "–§–ò–õ–¨–¢–†–´:–î–ê" in lines:
            result["has_filters"] = True
        elif "–§–ò–õ–¨–¢–†–´: –ù–ï–¢" in lines or "–§–ò–õ–¨–¢–†–´:–ù–ï–¢" in lines:
            result["has_filters"] = False
        
        # Try to extract authenticity score
        import re
        match = re.search(r'–ü–û–î–õ–ò–ù–ù–û–°–¢–¨[:\s]*(\d+)', lines)
        if match:
            result["authenticity_score"] = int(match.group(1))
            
    except Exception as e:
        result["error"] = f"GPT-4 Vision error: {str(e)}"
    
    return result


def analyze_with_sightengine(photo_url: Optional[str], image_base64: Optional[str]) -> dict:
    """Analyze photo using Sightengine API"""
    result = {
        "ai_generated": None,
        "quality_score": None,
        "face_detected": False,
        "face_quality": None,
        "face_obstruction": None,
        "face_angle": None,
        "face_filters": None,
        "sunglasses": None,
        "error": None
    }
    
    try:
        if image_base64:
            # Upload raw binary image
            image_bytes = get_image_bytes(None, image_base64)
            
            files = {
                'media': ('image.jpg', image_bytes, 'image/jpeg')
            }
            data = {
                'models': 'quality,genai,face-attributes',
                'api_user': SIGHTENGINE_USER,
                'api_secret': SIGHTENGINE_SECRET
            }
            
            response = requests.post(
                'https://api.sightengine.com/1.0/check.json',
                files=files,
                data=data,
                timeout=30
            )
        else:
            # Use URL
            params = {
                'url': photo_url,
                'models': 'quality,genai,face-attributes',
                'api_user': SIGHTENGINE_USER,
                'api_secret': SIGHTENGINE_SECRET
            }
            
            response = requests.get(
                'https://api.sightengine.com/1.0/check.json',
                params=params,
                timeout=30
            )
        
        data = response.json()
        
        if data.get("status") == "success":
            # Parse quality score (0-1 scale)
            if "quality" in data and "score" in data["quality"]:
                result["quality_score"] = round(data["quality"]["score"] * 100, 1)
            
            # Parse AI-generated score (0-1 scale, in "type" object)
            if "type" in data and "ai_generated" in data["type"]:
                result["ai_generated"] = round(data["type"]["ai_generated"] * 100, 1)
            
            # Parse face attributes
            if "faces" in data and len(data["faces"]) > 0:
                result["face_detected"] = True
                face = data["faces"][0]
                
                # Get face attributes
                if "attributes" in face:
                    attrs = face["attributes"]
                    result["face_quality"] = attrs.get("quality", "unknown")
                    result["face_obstruction"] = attrs.get("obstruction", "unknown")
                    result["face_angle"] = attrs.get("angle", "unknown")
                    # IMPORTANT: filters is a boolean
                    result["face_filters"] = attrs.get("filters", None)
                
                # Check for sunglasses
                if "sunglasses" in face:
                    result["sunglasses"] = face["sunglasses"]
        else:
            result["error"] = data.get("error", {}).get("message", "Unknown error")
            
    except requests.exceptions.Timeout:
        result["error"] = "Sightengine API timeout"
    except Exception as e:
        result["error"] = f"Sightengine error: {str(e)}"
    
    return result


def analyze_with_hive(photo_url: Optional[str], image_base64: Optional[str]) -> dict:
    """Analyze photo using Hive AI API for AI-generated detection"""
    result = {
        "ai_generated": None,
        "ai_source": None,
        "deepfake": None,
        "error": None
    }
    
    try:
        headers = {
            "Authorization": f"Token {HIVE_API_KEY}"
        }
        
        if image_base64:
            # Upload as multipart form data
            image_bytes = get_image_bytes(None, image_base64)
            
            files = {
                'media': ('image.jpg', image_bytes, 'image/jpeg')
            }
            
            response = requests.post(
                "https://api.thehive.ai/api/v2/task/sync",
                headers=headers,
                files=files,
                timeout=30
            )
        else:
            # Use URL - IMPORTANT: use data= not json=
            payload = {"url": photo_url}
            
            response = requests.post(
                "https://api.thehive.ai/api/v2/task/sync",
                headers=headers,
                data=payload,  # Changed from json= to data=
                timeout=30
            )
        
        data = response.json()
        
        # Parse Hive AI response
        # Response structure: status[0].response.output[0].classes[]
        if "status" in data and isinstance(data["status"], list) and len(data["status"]) > 0:
            status_item = data["status"][0]
            
            # Check for error in status
            if "status" in status_item:
                inner_status = status_item["status"]
                if inner_status.get("code") != "0":
                    result["error"] = inner_status.get("message", "Unknown Hive error")
                    return result
            
            if "response" in status_item and "output" in status_item["response"]:
                output = status_item["response"]["output"]
                
                if len(output) > 0 and "classes" in output[0]:
                    classes = output[0]["classes"]
                    
                    ai_generated_score = None
                    best_source = None
                    best_source_score = 0
                    deepfake_score = None
                    
                    # List of known AI generators
                    ai_generators = [
                        "sora", "pika", "haiper", "kling", "luma", "hedra", "runway",
                        "hailuo", "mochi", "flux", "hallo", "hunyuan", "recraft",
                        "leonardo", "luminagpt", "var", "liveportrait", "mcnet",
                        "pyramidflows", "sadtalker", "aniportrait", "cogvideos",
                        "makeittalk", "sdxlinpaint", "stablediffusioninpaint",
                        "bingimagecreator", "adobefirefly", "lcm", "dalle", "pixart",
                        "glide", "stablediffusion", "imagen", "amused", "stablecascade",
                        "midjourney", "deepfloyd", "gan", "stablediffusionxl",
                        "vqdiffusion", "kandinsky", "wuerstchen", "titan", "ideogram",
                        "sana", "emu3", "omnigen", "flashvideo", "transpixar", "cosmos",
                        "janus", "dmd2", "switti", "4o", "grok", "wan", "infinity",
                        "veo3", "imagen4", "other_image_generators"
                    ]
                    
                    for cls in classes:
                        class_name = cls.get("class", "")
                        score = cls.get("score", 0)
                        
                        # Get AI-generated score
                        if class_name == "ai_generated":
                            ai_generated_score = score
                        
                        # Get deepfake score
                        if class_name == "deepfake":
                            deepfake_score = score
                        
                        # Find the best matching AI source
                        if class_name in ai_generators and score > best_source_score:
                            best_source = class_name
                            best_source_score = score
                    
                    if ai_generated_score is not None:
                        result["ai_generated"] = round(ai_generated_score * 100, 1)
                    
                    if deepfake_score is not None:
                        result["deepfake"] = round(deepfake_score * 100, 1)
                    
                    if best_source and best_source_score > 0.1:
                        result["ai_source"] = f"{best_source} ({round(best_source_score * 100, 1)}%)"
                                
    except requests.exceptions.Timeout:
        result["error"] = "Hive API timeout"
    except Exception as e:
        result["error"] = f"Hive error: {str(e)}"
    
    return result


def format_analysis_result(sightengine_result: dict, hive_result: dict, gpt_result: dict) -> str:
    """Format the analysis results in Russian with emoji"""
    lines = []
    
    lines.append("üì∏ **–ê–ù–ê–õ–ò–ó –§–û–¢–û–ì–†–ê–§–ò–ò**")
    lines.append("")
    
    # Filter Detection Section (MOST IMPORTANT)
    lines.append("üé≠ **–§–∏–ª—å—Ç—Ä—ã –∏ –º–∞—Å–∫–∏:**")
    
    # GPT-4 Vision filter detection
    if gpt_result.get("has_filters") is True:
        lines.append(f"  ‚Ä¢ GPT-4 Vision: ‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Ñ–∏–ª—å—Ç—Ä—ã")
    elif gpt_result.get("has_filters") is False:
        lines.append(f"  ‚Ä¢ GPT-4 Vision: ‚ùå –§–∏–ª—å—Ç—Ä—ã –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")
    else:
        lines.append(f"  ‚Ä¢ GPT-4 Vision: –î–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
    
    # Sightengine filter detection
    if sightengine_result.get("face_filters") is True:
        lines.append(f"  ‚Ä¢ Sightengine: ‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Ñ–∏–ª—å—Ç—Ä—ã –Ω–∞ –ª–∏—Ü–µ")
    elif sightengine_result.get("face_filters") is False:
        lines.append(f"  ‚Ä¢ Sightengine: ‚ùå –§–∏–ª—å—Ç—Ä—ã –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")
    else:
        if sightengine_result.get("face_detected"):
            lines.append(f"  ‚Ä¢ Sightengine: –î–∞–Ω–Ω—ã–µ –æ —Ñ–∏–ª—å—Ç—Ä–∞—Ö –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
    
    lines.append("")
    
    # AI Generation Detection Section
    lines.append("ü§ñ **–ò–ò-–≥–µ–Ω–µ—Ä–∞—Ü–∏—è (–ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –ò–ò):**")
    
    # Sightengine AI detection
    if sightengine_result.get("ai_generated") is not None:
        ai_score = sightengine_result["ai_generated"]
        if ai_score < 20:
            verdict = "‚úÖ –†–µ–∞–ª—å–Ω–æ–µ —Ñ–æ—Ç–æ"
        elif ai_score < 50:
            verdict = "‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞"
        else:
            verdict = "üö® –í–µ—Ä–æ—è—Ç–Ω–æ –ò–ò"
        lines.append(f"  ‚Ä¢ Sightengine: {ai_score}% {verdict}")
    else:
        lines.append(f"  ‚Ä¢ Sightengine: –î–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
    
    # Hive AI detection
    if hive_result.get("ai_generated") is not None:
        ai_score = hive_result["ai_generated"]
        if ai_score < 20:
            verdict = "‚úÖ –†–µ–∞–ª—å–Ω–æ–µ —Ñ–æ—Ç–æ"
        elif ai_score < 50:
            verdict = "‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞"
        else:
            verdict = "üö® –í–µ—Ä–æ—è—Ç–Ω–æ –ò–ò"
        lines.append(f"  ‚Ä¢ Hive AI: {ai_score}% {verdict}")
        
        if hive_result.get("ai_source"):
            lines.append(f"    –ò—Å—Ç–æ—á–Ω–∏–∫: {hive_result['ai_source']}")
    else:
        if hive_result.get("error"):
            lines.append(f"  ‚Ä¢ Hive AI: ‚ö†Ô∏è {hive_result['error'][:80]}")
        else:
            lines.append(f"  ‚Ä¢ Hive AI: –î–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
    
    # Deepfake detection
    if hive_result.get("deepfake") is not None:
        df_score = hive_result["deepfake"]
        if df_score < 20:
            verdict = "‚úÖ –ù–µ –¥–∏–ø—Ñ–µ–π–∫"
        elif df_score < 50:
            verdict = "‚ö†Ô∏è –í–æ–∑–º–æ–∂–µ–Ω –¥–∏–ø—Ñ–µ–π–∫"
        else:
            verdict = "üö® –í–µ—Ä–æ—è—Ç–Ω–æ –¥–∏–ø—Ñ–µ–π–∫"
        lines.append(f"  ‚Ä¢ –î–∏–ø—Ñ–µ–π–∫: {df_score}% {verdict}")
    
    lines.append("")
    
    # Quality Section
    lines.append("üìä **–ö–∞—á–µ—Å—Ç–≤–æ:**")
    if sightengine_result.get("quality_score") is not None:
        quality = sightengine_result["quality_score"]
        if quality >= 85:
            quality_text = "–û—Ç–ª–∏—á–Ω–æ–µ"
        elif quality >= 60:
            quality_text = "–•–æ—Ä–æ—à–µ–µ"
        elif quality >= 45:
            quality_text = "–°—Ä–µ–¥–Ω–µ–µ"
        else:
            quality_text = "–ù–∏–∑–∫–æ–µ"
        lines.append(f"  ‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ: {quality}/100 ({quality_text})")
    
    lines.append("")
    
    # Face Analysis Section
    lines.append("üë§ **–ê–Ω–∞–ª–∏–∑ –ª–∏—Ü–∞:**")
    if sightengine_result.get("face_detected"):
        lines.append(f"  ‚Ä¢ –õ–∏—Ü–æ: ‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
        
        face_quality = sightengine_result.get("face_quality")
        if face_quality:
            quality_map = {"perfect": "–ò–¥–µ–∞–ª—å–Ω–æ–µ", "high": "–í—ã—Å–æ–∫–æ–µ", "medium": "–°—Ä–µ–¥–Ω–µ–µ", "low": "–ù–∏–∑–∫–æ–µ"}
            lines.append(f"  ‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ –ª–∏—Ü–∞: {quality_map.get(face_quality, face_quality)}")
        
        face_obstruction = sightengine_result.get("face_obstruction")
        if face_obstruction:
            obstruction_map = {"none": "–ù–µ—Ç", "light": "–õ–µ–≥–∫–æ–µ", "medium": "–°—Ä–µ–¥–Ω–µ–µ", "heavy": "–°–∏–ª—å–Ω–æ–µ", "extreme": "–≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ–µ", "complete": "–ü–æ–ª–Ω–æ–µ"}
            lines.append(f"  ‚Ä¢ –ü—Ä–µ–ø—è—Ç—Å—Ç–≤–∏—è: {obstruction_map.get(face_obstruction, face_obstruction)}")
        
        sunglasses = sightengine_result.get("sunglasses")
        if sunglasses is not None:
            lines.append(f"  ‚Ä¢ –û—á–∫–∏: {'–î–∞' if sunglasses else '–ù–µ—Ç'}")
    else:
        lines.append(f"  ‚Ä¢ –õ–∏—Ü–æ: ‚ùå –ù–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
    
    lines.append("")
    
    # GPT-4 Vision detailed analysis
    if gpt_result.get("analysis"):
        lines.append("üîç **–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (GPT-4 Vision):**")
        # Add the analysis with proper indentation
        for line in gpt_result["analysis"].split('\n'):
            if line.strip():
                lines.append(f"  {line}")
    
    lines.append("")
    
    # Overall verdict
    lines.append("üìã **–ò–¢–û–ì:**")
    
    # Calculate overall authenticity
    authenticity_scores = []
    
    # From GPT-4 Vision
    if gpt_result.get("authenticity_score") is not None:
        authenticity_scores.append(gpt_result["authenticity_score"])
    
    # From AI detection (inverse)
    ai_scores = []
    if sightengine_result.get("ai_generated") is not None:
        ai_scores.append(sightengine_result["ai_generated"])
    if hive_result.get("ai_generated") is not None:
        ai_scores.append(hive_result["ai_generated"])
    
    if ai_scores:
        avg_ai = sum(ai_scores) / len(ai_scores)
        authenticity_scores.append(100 - avg_ai)
    
    # Determine filter penalty
    filter_penalty = 0
    if gpt_result.get("has_filters") is True:
        filter_penalty = 30
    elif sightengine_result.get("face_filters") is True:
        filter_penalty = 25
    
    if authenticity_scores:
        avg_authenticity = sum(authenticity_scores) / len(authenticity_scores)
        final_score = max(0, avg_authenticity - filter_penalty)
        
        if final_score >= 80:
            verdict = "‚úÖ –§–æ—Ç–æ –≤—ã–≥–ª—è–¥–∏—Ç –ø–æ–¥–ª–∏–Ω–Ω—ã–º"
        elif final_score >= 50:
            verdict = "‚ö†Ô∏è –§–æ—Ç–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏–ª–∏ —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏"
        else:
            verdict = "üö® –°–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–ª–∏ –ò–ò-–≥–µ–Ω–µ—Ä–∞—Ü–∏—è"
        
        lines.append(f"  ‚Ä¢ –ü–æ–¥–ª–∏–Ω–Ω–æ—Å—Ç—å: {round(final_score, 1)}%")
        lines.append(f"  ‚Ä¢ –í–µ—Ä–¥–∏–∫—Ç: {verdict}")
        
        if filter_penalty > 0:
            lines.append(f"  ‚Ä¢ –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Ñ–∏–ª—å—Ç—Ä—ã (-{filter_penalty}%)")
    else:
        lines.append(f"  ‚Ä¢ –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ü–µ–Ω–∫–∏")
    
    return "\n".join(lines)


@app.post("/analyze-photo")
async def analyze_photo(request: PhotoRequest):
    """Analyze photo for AI-generation, filters, quality, and face attributes"""
    try:
        # Validate input
        if not request.photo_url and not request.image_base64:
            raise HTTPException(
                status_code=400, 
                detail="Either photo_url or image_base64 must be provided"
            )
        
        # Run all analyses
        sightengine_result = analyze_with_sightengine(request.photo_url, request.image_base64)
        hive_result = analyze_with_hive(request.photo_url, request.image_base64)
        gpt_result = analyze_with_gpt4_vision(request.photo_url, request.image_base64)
        
        # Format the results
        formatted_result = format_analysis_result(sightengine_result, hive_result, gpt_result)
        
        return {
            "analysis": formatted_result,
            "debug": {
                "sightengine": sightengine_result,
                "hive": hive_result,
                "gpt_vision": {k: v for k, v in gpt_result.items() if k != "analysis"}
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500, 
            detail=f"Error analyzing photo: {str(e)}"
        )


@app.get("/health")
def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "sightengine_configured": bool(SIGHTENGINE_USER and SIGHTENGINE_SECRET),
        "hive_configured": bool(HIVE_API_KEY),
        "openai_configured": bool(os.getenv("OPENAI_API_KEY"))
    }
